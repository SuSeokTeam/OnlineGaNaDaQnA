package CONTROL;

import kr.ac.kaist.swrc.jhannanum.hannanum.Workflow;
import kr.ac.kaist.swrc.jhannanum.hannanum.WorkflowFactory;


import java.io.FileNotFoundException;
import java.io.IOException;

import kr.ac.kaist.swrc.jhannanum.hannanum.Workflow;
import kr.ac.kaist.swrc.jhannanum.plugin.MajorPlugin.MorphAnalyzer.ChartMorphAnalyzer.ChartMorphAnalyzer;
import kr.ac.kaist.swrc.jhannanum.plugin.MajorPlugin.PosTagger.HmmPosTagger.HMMTagger;
import kr.ac.kaist.swrc.jhannanum.plugin.SupplementPlugin.MorphemeProcessor.SimpleMAResult09.SimpleMAResult09;
import kr.ac.kaist.swrc.jhannanum.plugin.SupplementPlugin.MorphemeProcessor.SimpleMAResult22.SimpleMAResult22;
import kr.ac.kaist.swrc.jhannanum.plugin.SupplementPlugin.MorphemeProcessor.UnknownMorphProcessor.UnknownProcessor;
import kr.ac.kaist.swrc.jhannanum.plugin.SupplementPlugin.PlainTextProcessor.InformalSentenceFilter.InformalSentenceFilter;
import kr.ac.kaist.swrc.jhannanum.plugin.SupplementPlugin.PlainTextProcessor.SentenceSegmentor.SentenceSegmentor;
import kr.ac.kaist.swrc.jhannanum.plugin.SupplementPlugin.PosProcessor.SimplePOSResult09.SimplePOSResult09;
import kr.ac.kaist.swrc.jhannanum.plugin.SupplementPlugin.PosProcessor.SimplePOSResult22.SimplePOSResult22;


public class Hannanum {

	Workflow hannanumWordflow;
	
	public Hannanum()
	{
		hannanumWordflow = new Workflow();
		
		try {

			hannanumWordflow.appendPlainTextProcessor(new SentenceSegmentor(), null);
			hannanumWordflow.appendPlainTextProcessor(new InformalSentenceFilter(), null);
			hannanumWordflow.setMorphAnalyzer(new ChartMorphAnalyzer(), "conf/plugin/MajorPlugin/MorphAnalyzer/ChartMorphAnalyzer.json");
			hannanumWordflow.appendMorphemeProcessor(new UnknownProcessor(), null);
			hannanumWordflow.setPosTagger(new HMMTagger(), "conf/plugin/MajorPlugin/PosTagger/HmmPosTagger.json");
			hannanumWordflow.activateWorkflow(true);
			
		} catch (FileNotFoundException e) {
			e.printStackTrace();
			System.exit(0);
		} catch (IOException e) {
			e.printStackTrace();
			System.exit(0);
		} catch (Exception e) {
			e.printStackTrace();
		}
		
	}
	
	public void closeWordFlow()
	{
		hannanumWordflow.close();
	}
	
	public String getResult(String sentence)
	{
		String[] array = sentence.split("\n");
		String result = "";
		int length = array.length;
		
		for(int i=0; i<length; i++)
		{
			String tmp = array[i];
			if(tmp.contains("\t"))
			{
				String[] list = tmp.split("\t");
				tmp = list[1];
			}
			if(tmp.contains("/"))
			{
				result = result + tmp + "\n";
			}
		}
		
		return result;
	}
	
	public String extractVerb(String sentence)
	{
		
		if(sentence.contains("/P"))
		{
			String[] temp = sentence.split("/P");
			return 	temp[0];
		}
		return "";
	}
	
	public String extractNoun(String sentence)
	{
		
		if(sentence.contains("/N"))
		{
			String[] temp = sentence.split("/P");
			return 	temp[0];
		}
		return "";
	}

	
	public void setSetting()
	{
		
	}
	
	public void ManualWorkflowSetUp (String sentence) {
	
		hannanumWordflow.analyze(sentence);
		System.out.println(hannanumWordflow.getResultOfDocument());
			
	}
	

}



package kr.kaist.ir.korean.parser;

import java.util.HashMap;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.Map;

import kr.kaist.ir.korean.data.ConflictedWord;
import kr.kaist.ir.korean.data.TaggedSentence;
import kr.kaist.ir.korean.data.TaggedWord;
import kr.kaist.ir.korean.data.TaggedWord.FunctionalTag;
import kr.kaist.ir.korean.tagger.IntegratedTagger;
import kr.kaist.ir.korean.util.TagConverter;
import kr.kaist.ir.korean.util.TagConverter.TaggerType;

/**
 * 양쪽 방법론 모두의 결과에서 공통된 정보만을 취합. 이 과정에서 어절 분석 구조가 다를 경우, KKMA를 따르도록 한다. 이 과정에서
 * Root는 없어진다.
 * 
 * @author 김부근
 * @since 2014-08-05
 * @version 0.2.2.4
 */
public class IntegratedParser implements Parser {
	private Parser hParser, kParser;

	/**
	 * 사용할 두 종류의 구문 분석기를 정의하는 생성자.
	 * 
	 * @throws Exception
	 *             초기화가 실패할 경우 발생한다.
	 */
	public IntegratedParser() throws Exception {
		hParser = new HannanumParser();
		kParser = new KkokkomaParser();
	}

	/*
	 * (non-Javadoc)
	 * 
	 * @see kr.kaist.ir.korean.parser.Parser#dependencyOf(java.lang.String)
	 */
	@Override
	public TaggedSentence dependencyOf(String sentence) throws Exception {
		// 구문을 분석한다.
		TaggedSentence kValue = kParser.dependencyOf(sentence);
		TaggedSentence hValue = hParser.dependencyOf(sentence);
		TaggedSentence value = IntegratedTagger.integrateSentence(kValue,
				hValue);

		HashMap<TaggedWord, Integer> wordmap = new HashMap<TaggedWord, Integer>();
		int index = 0;

		for (TaggedWord w : value) {
			HashMap<Integer, String> kdep = new HashMap<Integer, String>();

			// 꼬꼬마의 분석 결과를 추가한다.
			Iterator<TaggedWord> it = ((ConflictedWord) w).getWordsOfBase();
			while (it.hasNext()) {
				TaggedWord word = it.next();
				wordmap.put(word, index);
				LinkedList<TaggedWord> dependents = word.getDependents();
				for (TaggedWord dep : dependents) {
					Integer i = wordmap.get(dep);
					if (i != null && i != index) {
						// 공통된 결과만을 넣기 위해서 우선은 저장하지 않고 모아둔다.
						kdep.put(i, dep.getRawTag());
					}
				}
			}

			// 한나눔의 분석 결과를 추가한다.
			it = ((ConflictedWord) w).getWordsOfRef();
			while (it.hasNext()) {
				TaggedWord word = it.next();
				wordmap.put(word, index);
				LinkedList<TaggedWord> dependents = word.getDependents();
				for (TaggedWord dep : dependents) {
					Integer i = wordmap.get(dep);
					// 정상적인 index이고 공통 결과라면 저장한다.
					if (i != null && i != index && kdep.containsKey(i)) {
						String kkmaRawTag = kdep.get(i);
						FunctionalTag kkmaTag = TagConverter.getDependencyTag(
								kkmaRawTag, TaggerType.KKMA);
						if (dep.getTag() == kkmaTag
								|| kkmaRawTag.contains("대상")) {
							w.addDependant(value.getWordAt(i), dep.getTag(),
									dep.getRawTag() + "/" + kkmaRawTag);
						}
					}
				}
			}

			index++;
		}

		return value;
	}

	/*
	 * (non-Javadoc)
	 * 
	 * @see kr.kaist.ir.korean.parser.Parser#addUserDictionary(java.util.Map)
	 */
	@Override
	public void addUserDictionary(Map<String, String> dict) {
		kParser.addUserDictionary(dict);
		hParser.addUserDictionary(dict);
	}

	/*
	 * (non-Javadoc)
	 * 
	 * @see kr.kaist.ir.korean.parser.Parser#addUserDictionary(java.lang.String,
	 * java.lang.String)
	 */
	@Override
	public void addUserDictionary(String morph, String tag) {
		kParser.addUserDictionary(morph, tag);
		hParser.addUserDictionary(morph, tag);
	}
}


package kr.kaist.ir.korean.parser;

import java.util.List;
import java.util.Map;

import kr.kaist.ir.korean.data.TaggedSentence;
import kr.kaist.ir.korean.data.TaggedWord;
import kr.kaist.ir.korean.data.TaggedWord.FunctionalTag;
import kr.kaist.ir.korean.tagger.KkokkomaTagger;
import kr.kaist.ir.korean.util.TagConverter;
import kr.kaist.ir.korean.util.TagConverter.TaggerType;

import org.snu.ids.ha.ma.Sentence;
import org.snu.ids.ha.sp.ParseTree;
import org.snu.ids.ha.sp.ParseTreeEdge;
import org.snu.ids.ha.sp.ParseTreeNode;

/**
 * 꾜꼬마 구문 분석기를 사용하는 구문 분석 클래스
 * 
 * @author 김부근
 * @since 2014-08-05
 * @version 0.2.2.4
 */
public class KkokkomaParser implements Parser {
	/** 꼬꼬마 구문분석기 */
	private org.snu.ids.ha.sp.Parser parser;
	/** 꼬꼬마 형태소 분석기 */
	private KkokkomaTagger tagger;

	/**
	 * 꼬꼬마 형태소 분석기와 구문분석기를 초기화하는 생성자
	 */
	public KkokkomaParser() {
		parser = org.snu.ids.ha.sp.Parser.getInstance();
		tagger = new KkokkomaTagger();
	}

	/*
	 * (non-Javadoc)
	 * 
	 * @see kr.kaist.ir.korean.parser.Parser#dependencyOf(java.lang.String)
	 */
	@Override
	public TaggedSentence dependencyOf(String sentence) throws Exception {
		// 형태소 분석을 실시하되, 양쪽 결과가 모두 필요하므로 꼬꼬마의 결과를 받고, 받은 결과를 토대로 TaggedSentence를
		// 생성한다.
		Sentence rawSentence = tagger.analyzeSentenceRaw(sentence).get(0);
		TaggedSentence value = tagger.parseResult(rawSentence);

		// 구문 분석을 실시한다.
		ParseTree parse = parser.parse(rawSentence);

		// 구문 분석 결과의 각 변의 양 끝점을 찾아 문장에 추가한다.
		List<ParseTreeEdge> edgeList = parse.getEdgeList();
		List<ParseTreeNode> nodeList = parse.getNodeList();
		for (ParseTreeEdge e : edgeList) {
			int from = rawSentence.indexOf(nodeList.get(e.getFromId())
					.getEojeol());
			int to = rawSentence.indexOf(nodeList.get(e.getToId()).getEojeol());
			if (from != -1 && to != -1) {
				TaggedWord thisWord = value.getWordAt(to);
				TaggedWord headWord = value.getWordAt(from);
				String rawTag = e.getRelation();
				FunctionalTag tag = TagConverter.getDependencyTag(rawTag,
						TaggerType.KKMA);

				headWord.addDependant(thisWord, tag, rawTag);
			} else if (to != -1) {
				// Root를 지정하고 있으므로 표기해준다.
				value.setRoot(to);
			}
		}

		return value;
	}

	/*
	 * (non-Javadoc)
	 * 
	 * @see kr.kaist.ir.korean.parser.Parser#addUserDictionary(java.util.Map)
	 */
	@Override
	public void addUserDictionary(Map<String, String> dict) {
		tagger.addUserDictionary(dict);
	}

	/*
	 * (non-Javadoc)
	 * 
	 * @see kr.kaist.ir.korean.parser.Parser#addUserDictionary(java.lang.String,
	 * java.lang.String)
	 */
	@Override
	public void addUserDictionary(String morph, String tag) {
		tagger.addUserDictionary(morph, tag);
	}
}



